{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVRjbw3ShSco",
        "outputId": "3755edf2-043a-44cc-f86a-bb3dc9905792"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'aiml-general-championship:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F71608%2F7895811%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240731%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240731T160003Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D96c5df5c9599d65577fdc4bd9081f0110dc50c675b0872c7913c5c9f05300cb0ebc74c79f07112231e488864d1c9ba1c0e7d9e72732033640ec443ecf3d0663434587c6590c586e34e4bf578a6b73c46b8f35ab28bf7f9a7792bf9e7e925ddf5ea1294e979536c888f6c066979cbb9fab480ae49a52d9b2b757a6c4eb01a2db472c047cb127c0e2db2ccd400d9ac441b93194411e3c0535ee581a40288b6d9e4a8bbe5036fdfd7691d039f0873a125c48c887b35ca418352079a8499ab6eb54aee3dda514ce4373208d9c14fa4865cff045c92bbc182e85c5944030cea63a84dd1dc8b8bf44057e14d6f3a70d514833b3003686a1769b709bbed20e50cfc1739'\n",
        "\n",
        "KAGGLE_WORKING_PATH = '/kaggle/working'\n",
        "CHUNK_SIZE = 40960\n",
        "\n",
        "# Ensure directories exist in writable paths\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path.split('/')[-1]\n",
        "    destination_path = os.path.join(KAGGLE_WORKING_PATH, directory)\n",
        "\n",
        "    try:\n",
        "        with urlopen(download_url) as response, NamedTemporaryFile(delete=False) as tfile:\n",
        "            total_length = response.headers.get('content-length')\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            while True:\n",
        "                data = response.read(CHUNK_SIZE)\n",
        "                if not data:\n",
        "                    break\n",
        "                tfile.write(data)\n",
        "                dl += len(data)\n",
        "                done = int(50 * dl / int(total_length)) if total_length else 0\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50 - done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "            print()\n",
        "\n",
        "            # Close the temporary file so it can be accessed by the extraction methods\n",
        "            tfile.close()\n",
        "\n",
        "            # Extract the downloaded file\n",
        "            if filename.endswith('.zip'):\n",
        "                with ZipFile(tfile.name) as zfile:\n",
        "                    zfile.extractall(destination_path)\n",
        "            else:\n",
        "                with tarfile.open(tfile.name) as tarfile_obj:\n",
        "                    tarfile_obj.extractall(destination_path)\n",
        "\n",
        "            print(f'Downloaded and uncompressed: {directory}')\n",
        "    except HTTPError:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "    except OSError:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "\n",
        "print('Data source import complete.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c40b9da2-c586-4fd9-a3ca-5bfd4b55c8e6"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# Python libraries\n",
        "import os\n",
        "import cv2\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# PyTorch libraries\n",
        "import torch\n",
        "from torch import optim, nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import models, transforms\n",
        "\n",
        "# Scikit-learn libraries\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Ensure results are reproducible\n",
        "np.random.seed(10)\n",
        "torch.manual_seed(10)\n",
        "torch.cuda.manual_seed(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5a8f919-a3b2-4855-92eb-eae26a2d7c67",
        "outputId": "aec7734f-14df-41a7-f6e2-7c5c6a85133e"
      },
      "outputs": [],
      "source": [
        "data_dir = \"/kaggle/input/aiml-general-championship\"\n",
        "print(os.listdir(data_dir))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a59dac0-0469-4277-97cf-91d3184db2f8"
      },
      "source": [
        "<h1>Loading Data... </h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0f8a1675-e8fe-4073-a708-81d5ff299e25"
      },
      "outputs": [],
      "source": [
        "# Define the directory containing the images\n",
        "img_data_dir = os.path.join(data_dir, \"KCDH2024_Training_Input_10K\", \"KCDH2024_Training_Input_10K\")\n",
        "\n",
        "# Get a list of all image file paths with a .jpg extension\n",
        "all_image_path = glob(os.path.join(img_data_dir, '*.jpg'))\n",
        "\n",
        "# Create a dictionary mapping image filenames to their paths\n",
        "imageid_path_dict = {\n",
        "    os.path.splitext(os.path.basename(x))[0]: x for x in all_image_path\n",
        "}\n",
        "\n",
        "# Define a dictionary mapping lesion types to their descriptions\n",
        "lesion_type_dict = {\n",
        "    'nv': 'Melanocytic nevi',\n",
        "    'mel': 'Dermatofibroma',\n",
        "    'bkl': 'Benign keratosis-like lesions',\n",
        "    'bcc': 'Basal cell carcinoma',\n",
        "    'akiec': 'Actinic keratoses',\n",
        "    'vasc': 'Vascular lesions',\n",
        "    'df': 'Dermatofibroma'\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fca57305-c2bb-46a1-8334-26860f85c74b",
        "outputId": "977a6e48-c142-4edd-fc1c-078602eec458"
      },
      "outputs": [],
      "source": [
        "len(imageid_path_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24c97e68-8a4d-47ef-8568-6301572606e9",
        "outputId": "3fa6175a-1a86-4f5c-9de9-176d176d3ddf"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread(imageid_path_dict[\"ISIC_0024308\"])\n",
        "img.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7fc46fa-902e-4f03-8121-bf9713b2ce46"
      },
      "outputs": [],
      "source": [
        "def compute_img_mean_std(image_paths):\n",
        "    \"\"\"\n",
        "        computing the mean and std of three channel on the whole dataset,\n",
        "        first we should normalize the image from 0-255 to 0-1\n",
        "    \"\"\"\n",
        "\n",
        "    img_h, img_w = 224, 224              # Size to resize..\n",
        "    imgs = []\n",
        "    means, stdevs = [], []\n",
        "\n",
        "    for i in tqdm(range(len(image_paths))):\n",
        "        img = cv2.imread(image_paths[i])\n",
        "        img = cv2.resize(img, (img_h, img_w))\n",
        "        imgs.append(img)\n",
        "\n",
        "    imgs = np.stack(imgs, axis=3)\n",
        "    print(imgs.shape)\n",
        "\n",
        "    imgs = imgs.astype(np.float32) / 255.\n",
        "\n",
        "    for i in range(3):\n",
        "        pixels = imgs[:, :, i, :].ravel()  # resize to one row\n",
        "        means.append(np.mean(pixels))\n",
        "        stdevs.append(np.std(pixels))\n",
        "\n",
        "    means.reverse()  # BGR --> RGB\n",
        "    stdevs.reverse()\n",
        "\n",
        "    print(\"normMean = {}\".format(means))\n",
        "    print(\"normStd = {}\".format(stdevs))\n",
        "    return means,stdevs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b214f0bb-9b9a-4056-87d0-2fcb3ceae02e"
      },
      "outputs": [],
      "source": [
        "# means , stdevs = compute_img_mean_std(all_image_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "951cf86b-ce11-4ffe-a8d5-05bce76a8b2f"
      },
      "outputs": [],
      "source": [
        "# Store Values to save time in future..\n",
        "norm_mean = [0.76696384, 0.54525656, 0.56884694]\n",
        "norm_std = [0.13945772, 0.15192385, 0.16916788]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b440bd71-d7b5-478c-ac87-6f805e6f1dc3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "c6b294f0-8314-4385-b301-4d2950aae9e7",
        "outputId": "9c1caf50-b878-4879-dddb-d48131bfb0d9"
      },
      "outputs": [],
      "source": [
        "lesion_db = pd.read_csv(os.path.join(data_dir, 'KCDH2024_Training_LesionGroupings.csv'))\n",
        "truth_db = pd.read_csv(os.path.join(data_dir, 'KCDH2024_Training_GroundTruth.csv'))\n",
        "\n",
        "df = pd.merge(lesion_db, truth_db, on = 'image', how = 'inner')\n",
        "df.drop(\"diagnosis_confirm_type\", axis = 1, inplace = True)\n",
        "df['path'] = df['image'].map(imageid_path_dict.get)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "11bd67f6-cb38-4565-8ee3-8da234bc54e6",
        "outputId": "ea92d7cb-7b4e-4db0-97a5-b6cad247eded"
      },
      "outputs": [],
      "source": [
        "# Remove the rows not containg path to images..\n",
        "df = df[df['path'].notna()]\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "8a1af7d5-f0dc-4757-abb1-0b41eb80c4a8",
        "outputId": "41692e28-be38-40e2-faea-ec5be970ce37"
      },
      "outputs": [],
      "source": [
        "# Convert 7 different columns of different lesisons to single ...\n",
        "\n",
        "cell_type_idx = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    cell_type_idx_row = row[\"MEL\"], row[\"NV\"], row[\"BCC\"], row[\"AKIEC\"], row[\"BKL\"], row[\"DF\"], row[\"VASC\"]\n",
        "    cell_type_idx.append(cell_type_idx_row.index(1))\n",
        "\n",
        "# Assign a new column..\n",
        "df[\"cell_type_idx\"] = cell_type_idx\n",
        "\n",
        "# Drop older columns..\n",
        "df.drop( columns = [\"MEL\", \"NV\", \"BCC\", \"AKIEC\", \"BKL\", \"DF\", \"VASC\"], inplace = True)\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5d85effd-a57f-4333-917b-9bd71efd85f2",
        "outputId": "2b3d6242-94f7-4184-eae3-5398e5022419"
      },
      "outputs": [],
      "source": [
        "# Determine how many images are associated with each lesion_id ?\n",
        "df_undup = df.groupby('lesion_id').count()\n",
        "\n",
        "# Filter out lesion_id's that have only one image associated with it\n",
        "df_undup = df_undup[df_undup['image'] == 1]\n",
        "df_undup.reset_index(inplace=True)\n",
        "df_undup.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "a8ac9dfc-9f52-4b5c-b8be-9d730ac9e35c",
        "outputId": "ba478794-de45-4dd0-bafd-590f0a7f57c1"
      },
      "outputs": [],
      "source": [
        "df_undup = df.groupby('lesion_id').count()\n",
        "df_undup.head()\n",
        "\n",
        "# Filter out lesion_id's that have only one image associated with it\n",
        "df_undup = df_undup[df_undup['image'] == 1]\n",
        "df_undup.reset_index(inplace=True)\n",
        "df_undup[:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "b35c408f-cc71-4dd0-bf2b-836f9e4b1ebc",
        "outputId": "22ff38f8-ce76-4ec7-a8c5-3945daea2bc1"
      },
      "outputs": [],
      "source": [
        "# Identify lesion_id's that have duplicate images and those that have only one image.\n",
        "def get_duplicates(x):\n",
        "    unique_list = list(df_undup['lesion_id'])\n",
        "    if x in unique_list:\n",
        "        return 'unduplicated'\n",
        "    else:\n",
        "        return 'duplicated'\n",
        "\n",
        "# Create a new colum that is a copy of the lesion_id column\n",
        "df['duplicates'] = df['lesion_id']\n",
        "# Apply the function to this new column\n",
        "df['duplicates'] = df['duplicates'].apply(get_duplicates)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "39273193-7dde-456a-a827-759c52031820",
        "outputId": "56b813fa-050a-4c29-c0ee-0e3476550321"
      },
      "outputs": [],
      "source": [
        "df['duplicates'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6ae5025-6eec-4616-a72a-9eb6bb6ad4b3"
      },
      "outputs": [],
      "source": [
        "# Filter out images that don't have duplicates (count = 1)  (Removed augmented images)\n",
        "# We will use this data to get validation set..\n",
        "df_undup = df[df['duplicates'] == 'unduplicated']\n",
        "df_undup.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "a38f0226-af35-4f6e-8ea2-053197731a73",
        "outputId": "f0cbec03-eb76-4bdb-ba31-850e924ce3bf"
      },
      "outputs": [],
      "source": [
        "# Create a val set using df as none of these images have augmented duplicates in the training set now..\n",
        "y = df_undup['cell_type_idx']\n",
        "_, df_val = train_test_split(df_undup, test_size=0.2, random_state=101, stratify=y)\n",
        "df_val.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0255feb-0fc2-4bc8-a1cd-8c5e4f317007"
      },
      "outputs": [],
      "source": [
        "df_val['cell_type_idx'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44d369f8-5367-4960-b1d2-a1bd1338c15d"
      },
      "outputs": [],
      "source": [
        "# Remove the validation rows from the original data to get training rows..\n",
        "\n",
        "# This function identifies if an image is part of the train or val set.\n",
        "def get_val_rows(x):\n",
        "    # create a list of all the lesion_id's in the val set\n",
        "    val_list = list(df_val['image'])\n",
        "    if str(x) in val_list:\n",
        "        return 'val'\n",
        "    else:\n",
        "        return 'train'\n",
        "\n",
        "# Identify train and val rows..\n",
        "# Create a new colum that is a copy of the image column\n",
        "df['train_or_val'] = df['image']\n",
        "\n",
        "# Apply the function to this new column\n",
        "df['train_or_val'] = df['train_or_val'].apply(get_val_rows)\n",
        "\n",
        "# Filter out training rows\n",
        "df_train = df[df['train_or_val'] == 'train']\n",
        "df_train = df_train.drop('train_or_val', axis = 1, inplace = False)\n",
        "print(len(df_train))\n",
        "print(len(df_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0d2ccb27-b509-4770-a076-399dd8eb92e0",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "df_train['cell_type_idx'].value_counts()\n",
        "\n",
        "# Duplicate rows to balance the number of rows in 7 classes..\n",
        "data_aug_rate = [6.3,1.025,13,19.8,6.1,56.4,47.7]\n",
        "\n",
        "# Iterate over unique values of 'cell_type_idx'\n",
        "for i in df_train['cell_type_idx'].unique():\n",
        "\n",
        "    if data_aug_rate[i] > 1:\n",
        "\n",
        "        # Filter the DataFrame for the current value of 'cell_type_idx'\n",
        "        filtered_df = df_train[df_train['cell_type_idx'] == i]\n",
        "\n",
        "        # Duplicate rows based on the data augmentation rate for this value of 'cell_type_idx'\n",
        "        duplicated_rows = filtered_df.sample(frac=data_aug_rate[i] - 1, replace=True)\n",
        "\n",
        "        # Concatenate the original DataFrame with the duplicated rows\n",
        "        df_train = pd.concat([df_train, duplicated_rows], ignore_index=True)\n",
        "\n",
        "df_train['cell_type_idx'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91da8f11-4bad-4b95-8186-f2f02ee1912e"
      },
      "source": [
        "<h1>DataSet Spliiting</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbVbuxAthSc4"
      },
      "outputs": [],
      "source": [
        "len(df_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a15096f3-dd3c-4619-9c72-60caca33a5ad"
      },
      "outputs": [],
      "source": [
        "# Split the test set again in a validation set and a true test set:\n",
        "\n",
        "df_val, df_test = train_test_split(df_val, test_size=0.5)\n",
        "df_train = df_train.reset_index()\n",
        "df_val = df_val.reset_index()\n",
        "df_test = df_test.reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6a26a7c9-1a3d-49f6-a7dd-ce909f363a55"
      },
      "outputs": [],
      "source": [
        "print(len(df_test))\n",
        "df_test['cell_type_idx'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "322b282d-4c86-4376-addd-51cd043cfb49"
      },
      "source": [
        "<h1>Define Model</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7b36d853-5649-4dbd-b99e-d013008f7c90"
      },
      "outputs": [],
      "source": [
        "# feature_extract is a boolean that defines finetuning or feature extracting.\n",
        "# If feature_extract = False, the model is finetuned and all model parameters are updated.\n",
        "# If feature_extract = True, only the last layer parameters are updated, the others remain fixed.\n",
        "\n",
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2430227-8d6c-45a3-b73b-a7280f5091e6"
      },
      "outputs": [],
      "source": [
        "\n",
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
        "    # Initialize these variables which will be set\n",
        "    model_ft = None\n",
        "    input_size = 0\n",
        "\n",
        "    if model_name == \"efficientnet\":\n",
        "        model_ft = models.efficientnet_b3(pretrained=True, progress=True)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        input_size = 224\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        exit()\n",
        "\n",
        "    return model_ft, input_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDKXPsvtLlCW"
      },
      "outputs": [],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "269c3eef-51cc-4816-b76f-7b799f1ae2ef"
      },
      "outputs": [],
      "source": [
        "# Define a new model variable..\n",
        "\n",
        "model_name = \"efficientnet\"\n",
        "num_classes = 7\n",
        "feature_extract = False\n",
        "# Initialize the model\n",
        "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
        "\n",
        "# Define the device:\n",
        "device = torch.device('cuda:0')\n",
        "# device = torch.device('cpu') # If using cpu\n",
        "# Put the model on the device:\n",
        "model = model_ft.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc6ed264-20e3-4738-a852-e56fa710caba"
      },
      "source": [
        "<H1>Augmenting Data...</H1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7523d804-777c-45d9-9c5e-fea359dca2d6"
      },
      "outputs": [],
      "source": [
        "# Define the transformation for training images\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((input_size, input_size)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(norm_mean, norm_std)\n",
        "])\n",
        "\n",
        "# Define the transformation for validation images\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((input_size, input_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(norm_mean, norm_std)\n",
        "])\n",
        "\n",
        "# Define the transformation for test images\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((input_size, input_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(norm_mean, norm_std)\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c770294a-3192-437e-a6ea-491246ccda2a"
      },
      "outputs": [],
      "source": [
        "# Define a pytorch dataloader for dataset..\n",
        "class HAM10000(Dataset):\n",
        "    def __init__(self, df, transform=None):\n",
        "        self.df = df\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Load data and get label\n",
        "        X = Image.open(self.df['path'][index])\n",
        "        y = torch.tensor(int(self.df['cell_type_idx'][index]))\n",
        "\n",
        "        if self.transform:\n",
        "            X = self.transform(X)\n",
        "\n",
        "        return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03bf71e2-b9f3-4d3e-b41f-5d60ee984b66"
      },
      "outputs": [],
      "source": [
        "# Define the training set using the table train_df and using the defined transitions (train_transform)\n",
        "training_set = HAM10000(df_train, transform=train_transform)\n",
        "train_loader = DataLoader(training_set, batch_size=32, shuffle=True, num_workers=4)\n",
        "\n",
        "# Same for the validation set:\n",
        "validation_set = HAM10000(df_val, transform=train_transform)\n",
        "val_loader = DataLoader(validation_set, batch_size=32, shuffle=False, num_workers=4)\n",
        "\n",
        "# Same for the test set:\n",
        "test_set = HAM10000(df_test, transform=train_transform)\n",
        "test_loader = DataLoader(test_set, batch_size=32, shuffle=False, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3364d0cb-439f-4364-895d-f589cf8caff6"
      },
      "outputs": [],
      "source": [
        "# this function is used during training process, to calculate the loss and accuracy\n",
        "class AverageMeter(object):\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04368d6e-67ea-4322-970f-f23baec8d359"
      },
      "outputs": [],
      "source": [
        "# Initialize lists to store total training loss and accuracy\n",
        "total_loss_train = []\n",
        "total_acc_train = []\n",
        "\n",
        "def train(train_loader, model, criterion, optimizer, epoch, threshold_batch=None):\n",
        "    \"\"\"\n",
        "    Train the model for one epoch.\n",
        "\n",
        "    Args:\n",
        "        train_loader (DataLoader): DataLoader for training data.\n",
        "        model (nn.Module): The model to be trained.\n",
        "        criterion (nn.Module): Loss function.\n",
        "        optimizer (Optimizer): Optimizer for updating model parameters.\n",
        "        epoch (int): Current epoch number.\n",
        "        threshold_batch (int, optional): Maximum number of batches to process.\n",
        "\n",
        "    Returns:\n",
        "        float: Average training loss.\n",
        "        float: Average training accuracy.\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    train_loss = AverageMeter()\n",
        "    train_acc = AverageMeter()\n",
        "    curr_iter = (epoch - 1) * len(train_loader)\n",
        "\n",
        "    for i, data in enumerate(train_loader):\n",
        "        # Break if the batch index exceeds the threshold\n",
        "        if threshold_batch and i >= threshold_batch:\n",
        "            break\n",
        "\n",
        "        images, labels = data\n",
        "        N = images.size(0)\n",
        "        images = Variable(images).to(device)\n",
        "        labels = Variable(labels).to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Compute loss and update model\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Compute accuracy\n",
        "        prediction = outputs.max(1, keepdim=True)[1]\n",
        "        train_acc.update(prediction.eq(labels.view_as(prediction)).sum().item() / N)\n",
        "        train_loss.update(loss.item())\n",
        "\n",
        "        curr_iter += 1\n",
        "\n",
        "        # Print progress every 100 iterations\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f'[Epoch {epoch}], [Iter {i + 1} / {len(train_loader)}], '\n",
        "                  f'[Train Loss {train_loss.avg:.5f}], [Train Acc {train_acc.avg:.5f}]')\n",
        "            total_loss_train.append(train_loss.avg)\n",
        "            total_acc_train.append(train_acc.avg)\n",
        "\n",
        "    return train_loss.avg, train_acc.avg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cf9d7a6-6a20-4285-96ef-6115387ea8b8"
      },
      "outputs": [],
      "source": [
        "def validate(val_loader, model, criterion, epoch):\n",
        "    \"\"\"\n",
        "    Validate the model on the validation dataset.\n",
        "\n",
        "    Args:\n",
        "        val_loader (DataLoader): DataLoader for validation data.\n",
        "        model (nn.Module): The model to be evaluated.\n",
        "        criterion (nn.Module): Loss function.\n",
        "        epoch (int): Current epoch number.\n",
        "\n",
        "    Returns:\n",
        "        list: List of validation loss values.\n",
        "        list: List of validation accuracy values.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    val_loss = AverageMeter()\n",
        "    val_acc = AverageMeter()\n",
        "\n",
        "    total_val_loss = []\n",
        "    total_val_acc = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, data in tqdm(enumerate(val_loader), desc=\"Validating\"):\n",
        "\n",
        "            images, labels = data\n",
        "            N = images.size(0)\n",
        "            images = Variable(images).to(device)\n",
        "            labels = Variable(labels).to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            prediction = outputs.max(1, keepdim=True)[1]\n",
        "\n",
        "            # Update validation accuracy and loss\n",
        "            val_acc.update(prediction.eq(labels.view_as(prediction)).sum().item() / N)\n",
        "            val_loss.update(criterion(outputs, labels).item())\n",
        "\n",
        "            # Store metrics every 3 iterations\n",
        "            if (i + 1) % 3 == 0:\n",
        "                total_val_acc.append(val_acc.avg)\n",
        "                total_val_loss.append(val_loss.avg)\n",
        "\n",
        "    print('------------------------------------------------------------')\n",
        "    print(f'[Epoch {epoch}], [Val Loss {val_loss.avg:.5f}], [Val Acc {val_acc.avg:.5f}]')\n",
        "    print('------------------------------------------------------------')\n",
        "\n",
        "    return total_val_loss, total_val_acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5a283e24-b1ee-40e9-9d81-baa3054d9afa",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Start Training..\n",
        "def train_model(epoch_num, lr, optimizer_func = optim.Adam, threshold_batch = None, criterion = nn.CrossEntropyLoss()):\n",
        "\n",
        "    best_val_acc = 0\n",
        "    total_loss_val, total_acc_val = [],[]\n",
        "    for epoch in tqdm(range(1, epoch_num+1)):\n",
        "\n",
        "        # set optimizer and loss function\n",
        "        optimizer = optimizer_func(model.parameters(), lr= lr)\n",
        "        criterion = criterion.to(device)\n",
        "\n",
        "        loss_train, acc_train = train(train_loader, model, criterion, optimizer, epoch, threshold_batch)\n",
        "        loss_val, acc_val = validate(val_loader, model, criterion , optimizer, epoch)\n",
        "        total_loss_val += loss_val\n",
        "        total_acc_val += acc_val\n",
        "    return total_loss_val, total_acc_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BA811jIahSc-"
      },
      "outputs": [],
      "source": [
        "# Store Training data..\n",
        "total_loss_val, total_acc_val = [],[]\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-ljPPn6hSc-"
      },
      "outputs": [],
      "source": [
        "# Training - 1st\n",
        "data = train_model(1,1e-3)\n",
        "total_loss_val += data[0]\n",
        "total_acc_val += data[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YeKk7OYRhSc-"
      },
      "outputs": [],
      "source": [
        "# Check results on test dataset..\n",
        "validate(test_loader, model, criterion, optimizer, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWf_PYiohSc-"
      },
      "outputs": [],
      "source": [
        "# Training - 2nd..\n",
        "train_model(1,1e-5,threshold_batch = 300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01d-6bE4hSc-"
      },
      "outputs": [],
      "source": [
        "# Check results on test dataset..\n",
        "validate(test_loader, model, criterion, optimizer, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crK7vz7ehSc_"
      },
      "outputs": [],
      "source": [
        "# Training - 3rd..\n",
        "train_model(1,1e-5,threshold_batch = 300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWDZJOXChSc_"
      },
      "outputs": [],
      "source": [
        "# Check results on test dataset..\n",
        "validate(test_loader, model, criterion, optimizer, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udCRmxXvhSc_"
      },
      "source": [
        "<h1> Analaysis Of Accuracies.. </h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_d6Mq4qLhSc_"
      },
      "outputs": [],
      "source": [
        "total_loss_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZX5DKWTBhSc_"
      },
      "outputs": [],
      "source": [
        "# Analysing accuracy and loss of validation data over the model..\n",
        "\n",
        "fig = plt.figure(num = 1)\n",
        "fig2 = fig.add_subplot(1,1,1)\n",
        "fig2.plot(total_acc_val, label = 'validation accuracy')\n",
        "fig2.plot(total_loss_val, label = 'validation loss')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GTViITMhSc_"
      },
      "outputs": [],
      "source": [
        "# Analysing accuracy and loss of training data over the model..\n",
        "\n",
        "fig = plt.figure(num=1)\n",
        "fig1 = fig.add_subplot(1,1,1)\n",
        "fig1.plot(total_acc_train, label = 'training accuracy')\n",
        "fig1.plot(total_loss_train, label = 'training loss')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3EBQiOxohSc_"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ecj4dKyThSc_"
      },
      "outputs": [],
      "source": [
        "# Validation data evaluation\n",
        "\n",
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Initialize lists to store true labels and predictions\n",
        "y_label = []\n",
        "y_predict = []\n",
        "\n",
        "# Disable gradient computation\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(val_loader):\n",
        "        images, labels = data\n",
        "        images = Variable(images).to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        prediction = outputs.max(1, keepdim=True)[1]\n",
        "\n",
        "        # Append labels and predictions to the lists\n",
        "        y_label.extend(labels.cpu().numpy())\n",
        "        y_predict.extend(prediction.cpu().numpy().squeeze())\n",
        "\n",
        "# Compute the confusion matrix\n",
        "confusion_mtx = confusion_matrix(y_label, y_predict)\n",
        "\n",
        "# Define labels for plotting\n",
        "plot_labels = ['akiec', 'bcc', 'bkl', 'df', 'nv', 'vasc', 'mel']\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plot_confusion_matrix(confusion_mtx, plot_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTgzAH_ZhSc_"
      },
      "outputs": [],
      "source": [
        "# Test data evaluation\n",
        "\n",
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Initialize lists to store true labels and predictions\n",
        "test_y_label = []\n",
        "test_y_predict = []\n",
        "\n",
        "# Disable gradient computation\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        images = Variable(images).to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        prediction = outputs.max(1, keepdim=True)[1]\n",
        "        \n",
        "        # Append labels and predictions to the lists\n",
        "        test_y_label.extend(labels.cpu().numpy())\n",
        "        test_y_predict.extend(prediction.cpu().numpy().squeeze())\n",
        "\n",
        "# Compute the confusion matrix for the test data\n",
        "confusion_mtx_test = confusion_matrix(test_y_label, test_y_predict)\n",
        "\n",
        "# Define labels for plotting\n",
        "plot_labels = ['akiec', 'bcc', 'bkl', 'df', 'nv', 'vasc', 'mel']\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plot_confusion_matrix(confusion_mtx_test, plot_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMYTu0BxhSc_"
      },
      "outputs": [],
      "source": [
        "# Generate a validation classification report\n",
        "report = classification_report(y_label, y_predict, target_names=plot_labels)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eN-XERMhSc_"
      },
      "outputs": [],
      "source": [
        "# Generate a test classification report\n",
        "report = classification_report(test_y_label, test_y_predict, target_names=plot_labels)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zWOl2oqhSdA"
      },
      "outputs": [],
      "source": [
        "# True vs Incoorect classified analysis for validation data\n",
        "\n",
        "label_frac_error = 1 - np.diag(confusion_mtx) / np.sum(confusion_mtx, axis=1)\n",
        "plt.bar(np.arange(7),label_frac_error)\n",
        "plt.xlabel('True Label')\n",
        "plt.ylabel('Fraction classified incorrectly')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6Mq-e-3hSdA"
      },
      "outputs": [],
      "source": [
        "# True vs Incoorect classified analysis for test data\n",
        "\n",
        "label_frac_error = 1 - np.diag(confusion_mtx_test) / np.sum(confusion_mtx_test, axis=1)\n",
        "plt.bar(np.arange(7),label_frac_error)\n",
        "plt.xlabel('True Label')\n",
        "plt.ylabel('Fraction classified incorrectly')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3H7BIKDhSdA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJSMtp87hSdA"
      },
      "source": [
        "<h1> Predictions... </h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6790879-389d-4ff7-93d4-ddfe30320f3f"
      },
      "outputs": [],
      "source": [
        "# Get data..\n",
        "img_data_dir = data_dir + r\"/KCDH2024_Test_Input/KCDH2024_Test_Input\"\n",
        "all_image_path = glob(os.path.join(img_data_dir, '*.jpg'))\n",
        "imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x for x in all_image_path}  # key - image filename,   value - path to image\n",
        "len(imageid_path_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-Lu49i7hSdA"
      },
      "outputs": [],
      "source": [
        "# Header of txt file..\n",
        "text = \"ID,Class\\n\"\n",
        "\n",
        "# Rows ..\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for imagename, path in tqdm(imageid_path_dict.items()):\n",
        "         X = Image.open(path)\n",
        "         X = test_transform(X)\n",
        "         X = Variable(X).to(device)\n",
        "         output = model(X.unsqueeze(0))\n",
        "         prediction = output.max(1, keepdim=True)[1].item()\n",
        "         text += f\"{imagename},{prediction}\\n\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EC37DiUghSdA"
      },
      "outputs": [],
      "source": [
        "with open(f'predictions.csv', 'w') as txtfile:\n",
        "    txtfile.write(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gVOSy2PhSdA"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "databundleVersionId": 7895811,
          "sourceId": 71608,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30665,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
